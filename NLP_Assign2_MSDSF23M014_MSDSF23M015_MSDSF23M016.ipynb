{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy_KBiAuMAkB"
      },
      "outputs": [],
      "source": [
        "!pip install pdfplumber spacy python-docx pandas openpyxl\n",
        "!python -m spacy download en_core_web_sm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43dgdLlg46EZ",
        "outputId": "246893f1-b1fe-4f2e-c1ad-cc8399e1a733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Company Name', 'Company Website', 'Company Linkedin Page',\n",
            "       'Company Size', 'Type', 'Country Origion', 'Region of Origin',\n",
            "       'Company Culture', 'Industry', 'Fortune 500', 'G2K',\n",
            "       'Startup/Multinational', 'University Name', 'University  Type',\n",
            "       'University  Size', 'University   Ranking'],\n",
            "      dtype='object')\n",
            "Extracted Text: AYESHA AMEEN\n",
            "Software Engineer\n",
            "CONTACT SUMMARY\n",
            "Phone Seeking a software engineer position in a dynamic and innovative company\n",
            "+91 1234567890 where I can utilize my technical skills and knowledge to contribute to the growth\n",
            "of the organization. Professional highlights include:\n",
            "Location\n",
            "• 5+ years of experience in software development and programming\n",
            "Navi Mumbai, India\n",
            "• Strong expertise in Java, Python, and SQL\n",
            "Email\n",
            "• Knowledge of software development methodologies such as\n",
            "anisa.patel@email.com Agile and Scrum\n",
            "• Familiarity with web technologies such as HTML, CSS, and JavaScript\n",
            "LinkedIn\n",
            "linkedin.com/in/anisa.patel/ • Good understanding of database management and design principles\n",
            "• Ability to work independently and in a team environment\n",
            "• Excellent problem-solving and communication skills\n",
            "TECHNICAL\n",
            "SKILLS\n",
            "PROFESSIONAL EXPERIENCE\n",
            "Programming languages:\n",
            "• Java Software Engineer\n",
            "Infosys Ltd, Mumbai\n",
            "June 2018 - Present\n",
            "• Python\n",
            "• Developed and maintained applications using Java and Python\n",
            "• SQL\n",
            "• Designed and implemented relational databases using SQL\n",
            "Web technologies:\n",
            "• Collaborated with cross-functional teams to gather requirements and\n",
            "• HTML\n",
            "provide technical solutions\n",
            "• CSS\n",
            "• Participated in Agile software development methodologies such as Scrum\n",
            "• JavaScript and Kanban\n",
            "• Assisted in troubleshooting and fixing production issues in a timely manner\n",
            "Software development\n",
            "methodologies:\n",
            "• Agile Software Developer\n",
            "Wipro Technologies, Mumbai\n",
            "October 2016 - June 2018\n",
            "• Scrum\n",
            "• Designed and implemented web applications using HTML, CSS,\n",
            "and JavaScript\n",
            "• Worked on the integration of the front-end and back-end systems\n",
            "SOFT SKILLS\n",
            "• Assisted in the maintenance and improvement of existing applications\n",
            "• Provided technical support to end-users\n",
            "• Improved website responsiveness and user experience by implementing\n",
            "new design features and user interactions • Communication Software Developer Intern TCS, Mumbai\n",
            "August 2015 - September 2016\n",
            "• Interpersonal skills\n",
            "• Worked on various sof\n",
            "Processed CV: /content/CVs/Indian-Resume.pdf\n",
            "Extracted Companies: []\n",
            "Extracted Universities: []\n",
            "Extracted Experience: 8 years\n",
            "Rank: 8\n",
            "\n",
            "Extracted Text: AYESHA AMEEN\n",
            "Student.se13@gmail.co linkedin.com/in/ayesha-\n",
            "P +92-3091748218 E A Lahore in\n",
            "m ameen-962064167\n",
            "OBJECTIVE EDUCATION\n",
            "Seeking a DevOps role in a reputable organization, where I can apply my • BSc Software Engineering\n",
            "strong mathematical and problem-solving skills. I am Eager to contribute\n",
            "UET Taxila (2016-2020)\n",
            "to operational efficiency and continuous improvement in a collaborative\n",
            "CGPA: 3.22/4.00\n",
            "professional environment.\n",
            "• MPhil Data Science\n",
            "PUCIT, Lahore (2023-present)\n",
            "EXPERIENCE\n",
            "• Business Analyst and designer-Fiverr (Level 2 Seller) (April,2020-\n",
            "Present) KEY SKILLS\n",
            "• QA Engineer (Manual)- Oil & Natural Gas Corporation (India-\n",
            "Remote) (Oct,2021-Oct,2022) • CI/CD\n",
            "• QA Engineer & Content Writing – Tata Motors (Feb,2021- • Bash Scripting & Python\n",
            "Aug,2021) • Containerizations &\n",
            "Orchestration\n",
            "CERTIFICATIONS • Virtualization & Automation\n",
            "• Version Control systems\n",
            "• MOS certified (Microsoft Word, PowerPoint, Excel)\n",
            "• Cloud Platforms (GCPs)\n",
            "• E-rozgar Certified\n",
            "• Message Broker (Redis,\n",
            "PROJECTS RabbitMQ)\n",
            "• Communication skills\n",
            "- DOCKERIZED ML API HOSTING\n",
            "• Technical Aptitude\n",
            "Developed and deployed a Docker image hosting pre-trained regression models\n",
            "for predicting maximum and minimum temperatures based on a provided dataset.\n",
            "TOOLS\n",
            "Implemented RESTful API endpoints (/predict/max_t and /predict/min_t) for\n",
            "forecasting temperatures for a specified number of days.\n",
            "• Git\n",
            "- JENKINS CI/CD\n",
            "• Docker\n",
            "Established a CI/CD pipeline using Jenkins. Configured a secondary VM as a\n",
            "• Kubernetes\n",
            "Jenkins build agent with JRE and Docker engine, showcasing the build process\n",
            "• Vagrant\n",
            "by fetching code and Docker files from a Git repository.\n",
            "• Jenkins\n",
            "- Deployed Docassemble in a Load-Balanced (nginx) Environment\n",
            "• GitHub Actions\n",
            "- Prediction of Unemployment Rates Based on Historical data\n",
            "(1991-2021) by Using Linear Regression, Linear SVR & Gradient • Jupyter Notebook\n",
            "Boosting ML Model.\n",
            "- Awareness of IVF Treatments in Pakistan: Myths, Islamic\n",
            "Beliefs/Perspectives, and Youth Attitudes\n",
            "Processed CV: /content/CVs/Ayesha Ameen CV.pdf\n",
            "Extracted Companies: []\n",
            "Extracted Universities: []\n",
            "Extracted Experience: 0 years\n",
            "Rank: 0\n",
            "\n",
            "CV: Indian-Resume.pdf, Rank: 8, Experience: 8 years\n",
            "CV: Ayesha Ameen CV.pdf, Rank: 0, Experience: 0 years\n"
          ]
        }
      ],
      "source": [
        "import pdfplumber\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "import docx\n",
        "import re\n",
        "\n",
        "# Load the spacy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '/content/Dataset.xlsx'\n",
        "df = pd.read_excel(dataset_path)\n",
        "\n",
        "# Print the column names to understand the structure\n",
        "print(df.columns)\n",
        "\n",
        "# Split the dataframe into companies and universities\n",
        "top_companies = df[df['Type'] == 'Company']\n",
        "top_universities = df[df['Type'] == 'University']\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(file_path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(file_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \" \"\n",
        "    return text\n",
        "\n",
        "# Function to extract text from DOCX\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    text = \"\"\n",
        "    for paragraph in doc.paragraphs:\n",
        "        text += paragraph.text + \" \"\n",
        "    return text\n",
        "\n",
        "# Function to extract companies and universities from text\n",
        "def extract_entities(text):\n",
        "    doc = nlp(text)\n",
        "    companies = []\n",
        "    universities = []\n",
        "\n",
        "    # Debugging: Print extracted text\n",
        "    print(f\"Extracted Text: {text[:2000]}\")\n",
        "\n",
        "    # Extract entities using spacy\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"ORG\":\n",
        "            for _, row in top_companies.iterrows():\n",
        "                if re.search(re.escape(row['Company Name']), ent.text, re.IGNORECASE):\n",
        "                    companies.append((row['Company Name'], row['Fortune 500']))\n",
        "            for _, row in top_universities.iterrows():\n",
        "                if re.search(re.escape(row['University Name']), ent.text, re.IGNORECASE):\n",
        "                    universities.append((row['University Name'], row['University Ranking']))\n",
        "\n",
        "    # Regex matching as a fallback\n",
        "    for _, row in top_companies.iterrows():\n",
        "        if re.search(re.escape(row['Company Name']), text, re.IGNORECASE):\n",
        "            if (row['Company Name'], row['Fortune 500']) not in companies:\n",
        "                companies.append((row['Company Name'], row['Fortune 500']))\n",
        "\n",
        "    for _, row in top_universities.iterrows():\n",
        "        if re.search(re.escape(row['University Name']), text, re.IGNORECASE):\n",
        "            if (row['University Name'], row['University Ranking']) not in universities:\n",
        "                universities.append((row['University Name'], row['University Ranking']))\n",
        "\n",
        "    return companies, universities\n",
        "\n",
        "# Function to extract years of experience\n",
        "def extract_years_of_experience(text):\n",
        "    doc = nlp(text)\n",
        "    current_year = datetime.now().year\n",
        "    years = []\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"DATE\":\n",
        "            try:\n",
        "                year = int(ent.text.strip())\n",
        "                if 1950 <= year <= current_year:\n",
        "                    years.append(year)\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "    if len(years) >= 2:\n",
        "        total_experience = max(years) - min(years)\n",
        "    else:\n",
        "        total_experience = 0\n",
        "    return total_experience\n",
        "\n",
        "# Function to rank CV based on extracted information\n",
        "def rank_cv(companies, universities, experience):\n",
        "    company_score = sum([int(company[1]) for company in companies if pd.notnull(company[1])])\n",
        "    university_score = sum([int(university[1]) for university in universities if pd.notnull(university[1])])\n",
        "    experience_score = experience\n",
        "    return company_score + university_score + experience_score\n",
        "\n",
        "# Function to process a single CV\n",
        "def process_cv(file_path):\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        text = extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        text = extract_text_from_docx(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "    companies, universities = extract_entities(text)\n",
        "    experience = extract_years_of_experience(text)\n",
        "    rank = rank_cv(companies, universities, experience)\n",
        "\n",
        "    # Print extracted details for debugging\n",
        "    print(f\"Processed CV: {file_path}\")\n",
        "    print(f\"Extracted Companies: {companies}\")\n",
        "    print(f\"Extracted Universities: {universities}\")\n",
        "    print(f\"Extracted Experience: {experience} years\")\n",
        "    print(f\"Rank: {rank}\\n\")\n",
        "\n",
        "    return {\n",
        "        \"companies\": companies,\n",
        "        \"universities\": universities,\n",
        "        \"experience\": experience,\n",
        "        \"rank\": rank\n",
        "    }\n",
        "\n",
        "# Function to process all CVs in a directory\n",
        "def process_all_cvs(cv_directory):\n",
        "    cv_rankings = []\n",
        "    for cv_file in os.listdir(cv_directory):\n",
        "        if cv_file.endswith(\".pdf\") or cv_file.endswith(\".docx\"):\n",
        "            cv_data = process_cv(os.path.join(cv_directory, cv_file))\n",
        "            cv_rankings.append((cv_file, cv_data))\n",
        "\n",
        "    # Sort CVs by rank\n",
        "    cv_rankings.sort(key=lambda x: x[1][\"rank\"], reverse=True)\n",
        "    return cv_rankings\n",
        "\n",
        "\n",
        "cv_directory = \"/content/CVs\"\n",
        "ranked_cvs = process_all_cvs(cv_directory)\n",
        "\n",
        "for cv in ranked_cvs:\n",
        "    print(f\"CV: {cv[0]}, Rank: {cv[1]['rank']}, Experience: {cv[1]['experience']} years\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}