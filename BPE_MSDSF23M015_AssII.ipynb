{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f68eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bpe in c:\\users\\maham\\appdata\\roaming\\python\\python311\\site-packages (1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: nltk in c:\\users\\maham\\anaconda3\\lib\\site-packages (from bpe) (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\maham\\anaconda3\\lib\\site-packages (from bpe) (4.65.0)\n",
      "Requirement already satisfied: pytest in c:\\users\\maham\\anaconda3\\lib\\site-packages (from bpe) (7.4.0)\n",
      "Requirement already satisfied: hypothesis in c:\\users\\maham\\appdata\\roaming\\python\\python311\\site-packages (from bpe) (6.99.13)\n",
      "Requirement already satisfied: toolz in c:\\users\\maham\\anaconda3\\lib\\site-packages (from bpe) (0.12.0)\n",
      "Requirement already satisfied: mypy in c:\\users\\maham\\appdata\\roaming\\python\\python311\\site-packages (from bpe) (1.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\maham\\appdata\\roaming\\python\\python311\\site-packages (from hypothesis->bpe) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in c:\\users\\maham\\anaconda3\\lib\\site-packages (from hypothesis->bpe) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\maham\\anaconda3\\lib\\site-packages (from mypy->bpe) (4.7.1)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in c:\\users\\maham\\anaconda3\\lib\\site-packages (from mypy->bpe) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\maham\\anaconda3\\lib\\site-packages (from nltk->bpe) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\maham\\anaconda3\\lib\\site-packages (from nltk->bpe) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\maham\\anaconda3\\lib\\site-packages (from nltk->bpe) (2022.7.9)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\maham\\anaconda3\\lib\\site-packages (from pytest->bpe) (1.1.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\maham\\anaconda3\\lib\\site-packages (from pytest->bpe) (23.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\maham\\anaconda3\\lib\\site-packages (from pytest->bpe) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\maham\\anaconda3\\lib\\site-packages (from pytest->bpe) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install --user bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2c57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({' ': 147, 'ا': 85, 'ی': 68, 'ر': 53, 'ک': 39, 'ن': 35, 'و': 33, 'م': 31, 'ل': 29, 'ے': 21, 'د': 21, 'ع': 17, 'ف': 17, 'ہ': 16, 'ت': 16, 'س': 15, 'ج': 12, 'ب': 12, 'گ': 10, 'ں': 10, 'خ': 9, 'ز': 8, 'ص': 8, 'پ': 7, 'ش': 6, 'ئ': 6, 'ق': 5, 'آ': 5, 'ظ': 4, 'ح': 4, 'ھ': 3, 'ڑ': 2, 'ڈ': 2, 'ث': 1, 'ض': 1, 'ٹ': 1, '5': 1, '0': 1, 'چ': 1, '1': 1, '3': 1, 'ﷺ': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Combine all sentences into a single string\n",
    "corpus = \" \".join([\n",
    "    \"وزیراعظم عمران خان نے کل ایسی جگہ جانے کا فیصلہ کر لیا کہ اپوزیشن رہنما بھی دنگ\",\n",
    "    \"پاکستان کا یمن کے معاملے پر موثر کردار ادا کرنے کا فیصلہ صدر مملکت عارف علوی سابق وزیراعظم یوسف رضاگیلانی کے بھانجے کی گاڑی پر فائرن\",\n",
    "    \"علیم خان کی جائیدادیں ملک سے باہر تفصیلات آنے پر میرٹ پر کارروائی ہوگی ڈی جی\",\n",
    "    \"سرکاری افسر اکرام نوید نے50کروڑ چرائے اور شہباز شریف کے داماد علی عمران کو 13\",\n",
    "    \"وزیراعظم عمران خان نے ملک کی صورتحال میں بہتری کے لیے حتمی وقت دے دیاحالات\",\n",
    "    \"سیاسی جماعتیں اداروں کوگالیاں دینے والوں کیخلاف متحد ہوجائیں فیصل واڈا\",\n",
    "    \"عمران خان کو عاشق رسول ﷺ قرار دلوانے کیلئے فیصل آباد کے مولانا کودھمکیاں دی\",\n",
    "    \"نوازشریف کےخلاف فلیگ شپ ریفرنس کی سماعت آج ہوگی\",\n",
    "    \"آسیہ بی بی کی بیرون ملک روانگی کی خبریں درست نہیںترجمان دفترخارجہ\",\n",
    "    \"وزیراعظم عمران خان کی زیر صدارت وفاقی کابینہ کا اجلاس آج ہوگا\"\n",
    "])\n",
    "\n",
    "# Count the frequency of each character or character sequence\n",
    "char_counts = Counter(corpus)\n",
    "print(char_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e661c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pairs(text, pairs):\n",
    "    for pair in pairs:\n",
    "        a, b = pair\n",
    "        text = text.replace(a + b, a + b)\n",
    "    return text\n",
    "\n",
    "# Merge frequent pairs\n",
    "pairs = [(\"ا\", \"ع\"), (\"ع\", \"م\")]\n",
    "corpus_merged = merge_pairs(corpus, pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e25db7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "وزیر<UNK>ظم <UNK>ران خان نے کل ایسی جگہ جانے کا فیصلہ کر لیا کہ اپوزیشن رہنما بھی دنگ پاکستان کا یمن کے معاملے پر موثر کردار ادا کرنے کا فیصلہ صدر مملکت عارف علوی سابق وزیر<UNK>ظم یوسف رضاگیلانی کے بھانجے کی گاڑی پر فائرن علیم خان کی جائیدادیں ملک سے باہر تفصیلات آنے پر میرٹ پر کارروائی ہوگی ڈی جی سرکاری افسر اکرام نوید نے50کروڑ چرائے اور شہباز شریف کے داماد علی <UNK>ران کو 13 وزیر<UNK>ظم <UNK>ران خان نے ملک کی صورتحال میں بہتری کے لیے حتمی وقت دے دیاحالات سیاسی جم<UNK>تیں اداروں کوگالیاں دینے والوں کیخلاف متحد ہوجائیں فیصل واڈا <UNK>ران خان کو عاشق رسول ﷺ قرار دلوانے کیلئے فیصل آباد کے مولانا کودھمکیاں دی نوازشریف کےخلاف فلیگ شپ ریفرنس کی سم<UNK>ت آج ہوگی آسیہ بی بی کی بیرون ملک روانگی کی خبریں درست نہیںترجمان دفترخارجہ وزیر<UNK>ظم <UNK>ران خان کی زیر صدارت وفاقی کابینہ کا اجلاس آج ہوگا\n"
     ]
    }
   ],
   "source": [
    "# Replace merged pairs with a new token\n",
    "new_token = \"<UNK>\"\n",
    "encoded_corpus = corpus_merged.replace(\"اع\", new_token).replace(\"عم\", new_token)\n",
    "print(encoded_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca8adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"وزیراعظم عمران خان نے کل ایسی جگہ جانے کا فیصلہ کر لیا کہ اپوزیشن رہنما بھی دنگ\n",
    "پاکستان کا یمن کے معاملے پر موثر کردار ادا کرنے کا فیصلہ  صدر مملکت عارف علوی  سابق وزیراعظم یوسف رضاگیلانی کے بھانجے کی گاڑی پر فائرن\n",
    "علیم خان کی جائیدادیں ملک سے باہر  تفصیلات آنے پر میرٹ پر کارروائی ہوگی ڈی جی\n",
    "سرکاری افسر اکرام نوید نے50کروڑ چرائے اور شہباز شریف کے داماد علی عمران کو 13\n",
    "وزیراعظم عمران خان نے ملک کی صورتحال میں بہتری کے لیے حتمی وقت دے دیاحالات\n",
    "سیاسی جماعتیں اداروں کوگالیاں دینے والوں کیخلاف متحد ہوجائیں فیصل واڈا\n",
    "عمران خان کو عاشق رسول ﷺ قرار دلوانے کیلئے فیصل آباد کے مولانا کودھمکیاں دی\n",
    "نوازشریف کےخلاف فلیگ شپ ریفرنس کی سماعت آج ہوگی\n",
    "آسیہ بی بی کی بیرون ملک روانگی کی خبریں درست نہیںترجمان دفترخارجہ\n",
    "وزیراعظم عمران خان کی زیر صدارت وفاقی کابینہ کا اجلاس آج ہوگ\"\"\"\n",
    "vocab = set(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9cd8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "char_freq = Counter(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b83dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_vocab_size = 1000  # Example desired vocabulary size\n",
    "while len(vocab) < desired_vocab_size:\n",
    "    # Implement steps 4 and 5 here\n",
    "    pair_freq = Counter()\n",
    "    for text in corpus:\n",
    "        for i in range(len(text) - 1):\n",
    "            pair = text[i:i+2]\n",
    "            pair_freq[pair] += 1\n",
    "    most_common_pairs = pair_freq.most_common(1)\n",
    "    if most_common_pairs:\n",
    "        most_common_pair = most_common_pairs[0][0]\n",
    "        new_subword = ''.join(most_common_pair)\n",
    "        vocab.add(new_subword)\n",
    "        # Update frequency counts for characters containing the merged pair\n",
    "        for text in corpus:\n",
    "            text = text.replace(most_common_pair, new_subword)\n",
    "            char_freq.update(text)\n",
    "    else:\n",
    "        break  # Break the loop if no pairs are found\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41847f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace text with subword units\n",
    "subword_corpus = []\n",
    "for text in corpus:\n",
    "    for subword in vocab:\n",
    "        text = text.replace(subword, f' {subword} ')\n",
    "    subword_corpus.append(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df650a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'س', 'ل', 'ث', '0', 'ت', ' ', 'ف', 'خ', 'ں', 'ٹ', 'ج', 'ح', 'د', 'ش', 'آ', 'ڈ', 'ڑ', 'ض', 'ر', 'ص', 'ق', 'م', 'ک', 'پ', 'ئ', '1', 'ن', 'ز', '\\n', 'ع', 'ظ', 'ی', 'ب', '5', 'گ', '3', 'ﷺ', 'چ', 'ہ', 'ے', 'و', 'ھ', 'ا'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary:\", vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5362cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character frequencies: Counter({' ': 141, 'ا': 84, 'ی': 68, 'ر': 53, 'ک': 39, 'ن': 35, 'و': 33, 'م': 31, 'ل': 29, 'ے': 21, 'د': 21, 'ع': 17, 'ف': 17, 'ہ': 16, 'ت': 16, 'س': 15, 'ج': 12, 'ب': 12, 'گ': 10, 'ں': 10, 'خ': 9, '\\n': 9, 'ز': 8, 'ص': 8, 'پ': 7, 'ش': 6, 'ئ': 6, 'ق': 5, 'آ': 5, 'ظ': 4, 'ح': 4, 'ھ': 3, 'ڑ': 2, 'ڈ': 2, 'ث': 1, 'ض': 1, 'ٹ': 1, '5': 1, '0': 1, 'چ': 1, '1': 1, '3': 1, 'ﷺ': 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"Character frequencies:\", char_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8ace109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subword corpus:\n",
      " و \n",
      " ز \n",
      " ی \n",
      " ر \n",
      " ا \n",
      " ع \n",
      " ظ \n",
      " م \n",
      "   \n",
      " ع \n",
      " م \n",
      " ر \n",
      " ا \n",
      " ن \n",
      "   \n",
      " خ \n",
      " ا \n",
      " ن \n",
      "   \n",
      " ن \n",
      " ے \n",
      "   \n",
      " ک \n",
      "   ل   \n",
      "   \n",
      " ا \n",
      " ی \n",
      "   س   \n",
      " ی \n",
      "   \n",
      " ج \n",
      " گ \n",
      " ہ \n",
      "   \n",
      " ج \n",
      " ا \n",
      " ن \n",
      " ے \n",
      "   \n",
      " ک \n",
      " ا \n",
      "   \n",
      " ف \n",
      " ی \n",
      " ص \n",
      "   ل   \n",
      " ہ \n",
      "   \n",
      " ک \n",
      " ر \n",
      "   \n",
      "   ل   \n",
      " ی \n",
      " ا \n",
      "   \n",
      " ک \n",
      " ہ \n",
      "   \n",
      " ا \n",
      " پ \n",
      " و \n",
      " ز \n",
      " ی \n",
      " ش \n",
      " ن \n",
      "   \n",
      " ر \n",
      " ہ \n",
      " ن \n",
      " م \n",
      " ا \n",
      "   \n",
      " ب \n",
      " ھ \n",
      " ی \n",
      "   \n",
      " د \n",
      " ن \n",
      " گ \n",
      " \n",
      " \n",
      " پ \n",
      " ا \n",
      " ک \n",
      "   س   \n",
      "   ت   \n",
      " ا \n",
      " ن \n",
      "   \n",
      " ک \n",
      " ا \n",
      "   \n",
      " ی \n",
      " م \n",
      " ن \n",
      "   \n",
      " ک \n",
      " ے \n",
      "   \n",
      " م \n",
      " ع \n",
      " ا \n",
      " م \n",
      "   ل   \n",
      " ے \n",
      "   \n",
      " پ \n",
      " ر \n",
      "   \n",
      " م \n",
      " و \n",
      "   ث   \n",
      " ر \n",
      "   \n",
      " ک \n",
      " ر \n",
      " د \n",
      " ا \n",
      " ر \n",
      "   \n",
      " ا \n",
      " د \n",
      " ا \n",
      "   \n",
      " ک \n",
      " ر \n",
      " ن \n",
      " ے \n",
      "   \n",
      " ک \n",
      " ا \n",
      "   \n",
      " ف \n",
      " ی \n",
      " ص \n",
      "   ل   \n",
      " ہ \n",
      "   \n",
      "   \n",
      " ص \n",
      " د \n",
      " ر \n",
      "   \n",
      " م \n",
      " م \n",
      "   ل   \n",
      " ک \n",
      "   ت   \n",
      "   \n",
      " ع \n",
      " ا \n",
      " ر \n",
      " ف \n",
      "   \n",
      " ع \n",
      "   ل   \n",
      " و \n",
      " ی \n",
      "   \n",
      "   \n",
      "   س   \n",
      " ا \n",
      " ب \n",
      " ق \n",
      "   \n",
      " و \n",
      " ز \n",
      " ی \n",
      " ر \n",
      " ا \n",
      " ع \n",
      " ظ \n",
      " م \n",
      "   \n",
      " ی \n",
      " و \n",
      "   س   \n",
      " ف \n",
      "   \n",
      " ر \n",
      " ض \n",
      " ا \n",
      " گ \n",
      " ی \n",
      "   ل   \n",
      " ا \n",
      " ن \n",
      " ی \n",
      "   \n",
      " ک \n",
      " ے \n",
      "   \n",
      " ب \n",
      " ھ \n",
      " ا \n",
      " ن \n",
      " ج \n",
      " ے \n",
      "   \n",
      " ک \n",
      " ی \n",
      "   \n",
      " گ \n",
      " ا \n",
      " ڑ \n",
      " ی \n",
      "   \n",
      " پ \n",
      " ر \n",
      "   \n",
      " ف \n",
      " ا \n",
      " ئ \n",
      " ر \n",
      " ن \n",
      " \n",
      " \n",
      " ع \n",
      "   ل   \n",
      " ی \n",
      " م \n",
      "   \n",
      " خ \n",
      " ا \n",
      " ن \n",
      "   \n",
      " ک \n",
      " ی \n",
      "   \n",
      " ج \n",
      " ا \n",
      " ئ \n",
      " ی \n",
      " د \n",
      " ا \n",
      " د \n",
      " ی \n",
      " ں \n",
      "   \n",
      " م \n",
      "   ل   \n",
      " ک \n",
      "   \n",
      "   س   \n",
      " ے \n",
      "   \n",
      " ب \n",
      " ا \n",
      " ہ \n",
      " ر \n",
      "   \n",
      "   \n",
      "   ت   \n",
      " ف \n",
      " ص \n",
      " ی \n",
      "   ل   \n",
      " ا \n",
      "   ت   \n",
      "   \n",
      " آ \n",
      " ن \n",
      " ے \n",
      "   \n",
      " پ \n",
      " ر \n",
      "   \n",
      " م \n",
      " ی \n",
      " ر \n",
      " ٹ \n",
      "   \n",
      " پ \n",
      " ر \n",
      "   \n",
      " ک \n",
      " ا \n",
      " ر \n",
      " ر \n",
      " و \n",
      " ا \n",
      " ئ \n",
      " ی \n",
      "   \n",
      " ہ \n",
      " و \n",
      " گ \n",
      " ی \n",
      "   \n",
      " ڈ \n",
      " ی \n",
      "   \n",
      " ج \n",
      " ی \n",
      " \n",
      " \n",
      "   س   \n",
      " ر \n",
      " ک \n",
      " ا \n",
      " ر \n",
      " ی \n",
      "   \n",
      " ا \n",
      " ف \n",
      "   س   \n",
      " ر \n",
      "   \n",
      " ا \n",
      " ک \n",
      " ر \n",
      " ا \n",
      " م \n",
      "   \n",
      " ن \n",
      " و \n",
      " ی \n",
      " د \n",
      "   \n",
      " ن \n",
      " ے \n",
      " 5 \n",
      "   0   \n",
      " ک \n",
      " ر \n",
      " و \n",
      " ڑ \n",
      "   \n",
      " چ \n",
      " ر \n",
      " ا \n",
      " ئ \n",
      " ے \n",
      "   \n",
      " ا \n",
      " و \n",
      " ر \n",
      "   \n",
      " ش \n",
      " ہ \n",
      " ب \n",
      " ا \n",
      " ز \n",
      "   \n",
      " ش \n",
      " ر \n",
      " ی \n",
      " ف \n",
      "   \n",
      " ک \n",
      " ے \n",
      "   \n",
      " د \n",
      " ا \n",
      " م \n",
      " ا \n",
      " د \n",
      "   \n",
      " ع \n",
      "   ل   \n",
      " ی \n",
      "   \n",
      " ع \n",
      " م \n",
      " ر \n",
      " ا \n",
      " ن \n",
      "   \n",
      " ک \n",
      " و \n",
      "   \n",
      " 1 \n",
      " 3 \n",
      " \n",
      " \n",
      " و \n",
      " ز \n",
      " ی \n",
      " ر \n",
      " ا \n",
      " ع \n",
      " ظ \n",
      " م \n",
      "   \n",
      " ع \n",
      " م \n",
      " ر \n",
      " ا \n",
      " ن \n",
      "   \n",
      " خ \n",
      " ا \n",
      " ن \n",
      "   \n",
      " ن \n",
      " ے \n",
      "   \n",
      " م \n",
      "   ل   \n",
      " ک \n",
      "   \n",
      " ک \n",
      " ی \n",
      "   \n",
      " ص \n",
      " و \n",
      " ر \n",
      "   ت   \n",
      " ح \n",
      " ا \n",
      "   ل   \n",
      "   \n",
      " م \n",
      " ی \n",
      " ں \n",
      "   \n",
      " ب \n",
      " ہ \n",
      "   ت   \n",
      " ر \n",
      " ی \n",
      "   \n",
      " ک \n",
      " ے \n",
      "   \n",
      "   ل   \n",
      " ی \n",
      " ے \n",
      "   \n",
      " ح \n",
      "   ت   \n",
      " م \n",
      " ی \n",
      "   \n",
      " و \n",
      " ق \n",
      "   ت   \n",
      "   \n",
      " د \n",
      " ے \n",
      "   \n",
      " د \n",
      " ی \n",
      " ا \n",
      " ح \n",
      " ا \n",
      "   ل   \n",
      " ا \n",
      "   ت   \n",
      " \n",
      " \n",
      "   س   \n",
      " ی \n",
      " ا \n",
      "   س   \n",
      " ی \n",
      "   \n",
      " ج \n",
      " م \n",
      " ا \n",
      " ع \n",
      "   ت   \n",
      " ی \n",
      " ں \n",
      "   \n",
      " ا \n",
      " د \n",
      " ا \n",
      " ر \n",
      " و \n",
      " ں \n",
      "   \n",
      " ک \n",
      " و \n",
      " گ \n",
      " ا \n",
      "   ل   \n",
      " ی \n",
      " ا \n",
      " ں \n",
      "   \n",
      " د \n",
      " ی \n",
      " ن \n",
      " ے \n",
      "   \n",
      " و \n",
      " ا \n",
      "   ل   \n",
      " و \n",
      " ں \n",
      "   \n",
      " ک \n",
      " ی \n",
      " خ \n",
      "   ل   \n",
      " ا \n",
      " ف \n",
      "   \n",
      " م \n",
      "   ت   \n",
      " ح \n",
      " د \n",
      "   \n",
      " ہ \n",
      " و \n",
      " ج \n",
      " ا \n",
      " ئ \n",
      " ی \n",
      " ں \n",
      "   \n",
      " ف \n",
      " ی \n",
      " ص \n",
      "   ل   \n",
      "   \n",
      " و \n",
      " ا \n",
      " ڈ \n",
      " ا \n",
      " \n",
      " \n",
      " ع \n",
      " م \n",
      " ر \n",
      " ا \n",
      " ن \n",
      "   \n",
      " خ \n",
      " ا \n",
      " ن \n",
      "   \n",
      " ک \n",
      " و \n",
      "   \n",
      " ع \n",
      " ا \n",
      " ش \n",
      " ق \n",
      "   \n",
      " ر \n",
      "   س   \n",
      " و \n",
      "   ل   \n",
      "   \n",
      " ﷺ \n",
      "   \n",
      " ق \n",
      " ر \n",
      " ا \n",
      " ر \n",
      "   \n",
      " د \n",
      "   ل   \n",
      " و \n",
      " ا \n",
      " ن \n",
      " ے \n",
      "   \n",
      " ک \n",
      " ی \n",
      "   ل   \n",
      " ئ \n",
      " ے \n",
      "   \n",
      " ف \n",
      " ی \n",
      " ص \n",
      "   ل   \n",
      "   \n",
      " آ \n",
      " ب \n",
      " ا \n",
      " د \n",
      "   \n",
      " ک \n",
      " ے \n",
      "   \n",
      " م \n",
      " و \n",
      "   ل   \n",
      " ا \n",
      " ن \n",
      " ا \n",
      "   \n",
      " ک \n",
      " و \n",
      " د \n",
      " ھ \n",
      " م \n",
      " ک \n",
      " ی \n",
      " ا \n",
      " ں \n",
      "   \n",
      " د \n",
      " ی \n",
      " \n",
      " \n",
      " ن \n",
      " و \n",
      " ا \n",
      " ز \n",
      " ش \n",
      " ر \n",
      " ی \n",
      " ف \n",
      "   \n",
      " ک \n",
      " ے \n",
      " خ \n",
      "   ل   \n",
      " ا \n",
      " ف \n",
      "   \n",
      " ف \n",
      "   ل   \n",
      " ی \n",
      " گ \n",
      "   \n",
      " ش \n",
      " پ \n",
      "   \n",
      " ر \n",
      " ی \n",
      " ف \n",
      " ر \n",
      " ن \n",
      "   س   \n",
      "   \n",
      " ک \n",
      " ی \n",
      "   \n",
      "   س   \n",
      " م \n",
      " ا \n",
      " ع \n",
      "   ت   \n",
      "   \n",
      " آ \n",
      " ج \n",
      "   \n",
      " ہ \n",
      " و \n",
      " گ \n",
      " ی \n",
      " \n",
      " \n",
      " آ \n",
      "   س   \n",
      " ی \n",
      " ہ \n",
      "   \n",
      " ب \n",
      " ی \n",
      "   \n",
      " ب \n",
      " ی \n",
      "   \n",
      " ک \n",
      " ی \n",
      "   \n",
      " ب \n",
      " ی \n",
      " ر \n",
      " و \n",
      " ن \n",
      "   \n",
      " م \n",
      "   ل   \n",
      " ک \n",
      "   \n",
      " ر \n",
      " و \n",
      " ا \n",
      " ن \n",
      " گ \n",
      " ی \n",
      "   \n",
      " ک \n",
      " ی \n",
      "   \n",
      " خ \n",
      " ب \n",
      " ر \n",
      " ی \n",
      " ں \n",
      "   \n",
      " د \n",
      " ر \n",
      "   س   \n",
      "   ت   \n",
      "   \n",
      " ن \n",
      " ہ \n",
      " ی \n",
      " ں \n",
      "   ت   \n",
      " ر \n",
      " ج \n",
      " م \n",
      " ا \n",
      " ن \n",
      "   \n",
      " د \n",
      " ف \n",
      "   ت   \n",
      " ر \n",
      " خ \n",
      " ا \n",
      " ر \n",
      " ج \n",
      " ہ \n",
      " \n",
      " \n",
      " و \n",
      " ز \n",
      " ی \n",
      " ر \n",
      " ا \n",
      " ع \n",
      " ظ \n",
      " م \n",
      "   \n",
      " ع \n",
      " م \n",
      " ر \n",
      " ا \n",
      " ن \n",
      "   \n",
      " خ \n",
      " ا \n",
      " ن \n",
      "   \n",
      " ک \n",
      " ی \n",
      "   \n",
      " ز \n",
      " ی \n",
      " ر \n",
      "   \n",
      " ص \n",
      " د \n",
      " ا \n",
      " ر \n",
      "   ت   \n",
      "   \n",
      " و \n",
      " ف \n",
      " ا \n",
      " ق \n",
      " ی \n",
      "   \n",
      " ک \n",
      " ا \n",
      " ب \n",
      " ی \n",
      " ن \n",
      " ہ \n",
      "   \n",
      " ک \n",
      " ا \n",
      "   \n",
      " ا \n",
      " ج \n",
      "   ل   \n",
      " ا \n",
      "   س   \n",
      "   \n",
      " آ \n",
      " ج \n",
      "   \n",
      " ہ \n",
      " و \n",
      " گ \n"
     ]
    }
   ],
   "source": [
    "print(\"Subword corpus:\")\n",
    "for text in subword_corpus:\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Function to apply Byte Pair Encoding (BPE) algorithm\n",
    "def apply_bpe(corpus, desired_vocab_size):\n",
    "    vocab = set()\n",
    "    char_freq = Counter()\n",
    "\n",
    "    # Repeat until desired vocabulary size is reached\n",
    "    while len(vocab) < desired_vocab_size:\n",
    "        # Calculate pair frequencies\n",
    "        pair_freq = Counter()\n",
    "        for text in corpus:\n",
    "            for i in range(len(text) - 1):\n",
    "                pair = text[i:i+2]\n",
    "                pair_freq[pair] += 1\n",
    "\n",
    "        # Get the most frequent pair\n",
    "        most_common_pairs = pair_freq.most_common(1)\n",
    "        if not most_common_pairs:\n",
    "            break\n",
    "        most_common_pair = most_common_pairs[0][0]\n",
    "        new_subword = ''.join(most_common_pair)\n",
    "        vocab.add(new_subword)\n",
    "\n",
    "        # Update frequency counts for characters containing the merged pair\n",
    "        for text in corpus:\n",
    "            text = text.replace(most_common_pair, new_subword)\n",
    "            char_freq.update(text)\n",
    "\n",
    "    # Represent the text corpus using the subword units in the vocabulary\n",
    "    subword_corpus = []\n",
    "    for text in corpus:\n",
    "        for subword in vocab:\n",
    "            text = text.replace(subword, f' {subword} ')\n",
    "        subword_corpus.append(text)\n",
    "\n",
    "    return vocab, subword_corpus\n",
    "\n",
    "\n",
    "# Example training corpus\n",
    "training_corpus = [\n",
    "    \"وزیراعظم عمران خان نے کل ایسی جگہ جانے کا فیصلہ کر لیا کہ اپوزیشن رہنما بھی دنگ\",\n",
    "    \"پاکستان کا یمن کے معاملے پر موثر کردار ادا کرنے کا فیصلہ  صدر مملکت عارف علوی  سابق وزیراعظم یوسف رضاگیلانی کے بھانجے کی گاڑی پر فائرن\",\n",
    "    \"علیم خان کی جائیدادیں ملک سے باہر  تفصیلات آنے پر میرٹ پر کارروائی ہوگی ڈی جی\",\n",
    "    \"سرکاری افسر اکرام نوید نے50کروڑ چرائے اور شہباز شریف کے داماد علی عمران کو 13\",\n",
    "    \"وزیراعظم عمران خان نے ملک کی صورتحال میں بہتری کے لیے حتمی وقت دے دیاحالات\",\n",
    "    \"سیاسی جماعتیں اداروں کوگالیاں دینے والوں کیخلاف متحد ہوجائیں فیصل واڈا\",\n",
    "    \"عمران خان کو عاشق رسول ﷺ قرار دلوانے کیلئے فیصل آباد کے مولانا کودھمکیاں دی\",\n",
    "    \"نوازشریف کےخلاف فلیگ شپ ریفرنس کی سماعت آج ہوگی\",\n",
    "    \"آسیہ بی بی کی بیرون ملک روانگی کی خبریں درست نہیںترجمان دفترخارجہ\",\n",
    "    \"وزیراعظم عمران خان کی زیر صدارت وفاقی کابینہ کا اجلاس آج ہوگا\"\n",
    "]\n",
    "\n",
    "# Training BPE on training corpus\n",
    "desired_vocab_size = 1000  # Example desired vocabulary size\n",
    "vocab, subword_corpus = apply_bpe(training_corpus, desired_vocab_size)\n",
    "\n",
    "# Print vocabulary and subword corpus\n",
    "print(\"Vocabulary:\", vocab)\n",
    "print(\"\\nSubword Corpus:\")\n",
    "for text in subword_corpus:\n",
    "    print(text)\n",
    "\n",
    "# Example test corpus\n",
    "test_corpus = [\n",
    "    \"وزیراعظم عمران خان کل جلسے کریں گے\",\n",
    "    \"عمران خان کو عاشق رسول ﷺ قرار دلوانے کیلئے کونسی ملترہ دی؟\"\n",
    "]\n",
    "\n",
    "# Represent test data using the same subword vocabulary\n",
    "subword_test_corpus = []\n",
    "for text in test_corpus:\n",
    "    for subword in vocab:\n",
    "        text = text.replace(subword, f' {subword} ')\n",
    "    subword_test_corpus.append(text)\n",
    "\n",
    "# Print subword test corpus\n",
    "print(\"\\nSubword Test Corpus:\")\n",
    "for text in subword_test_corpus:\n",
    "    print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae8d69f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['وزیراعظم', 'عمران', 'خان', 'نے', 'کل', '__sow', 'ا', 'ی', 'ک', '__eow', '__sow', 'م', 'ق', 'ام', '__eow', 'پر', 'جانے', 'کا', 'فیصلہ', '__sow', 'کی', 'ا', '__eow', '__sow', 'ہ', 'ے', '__eow', '__sow', '__unk', '__eow', '__sow', 'ج', 'ہ', 'اں', '__eow', '__sow', 'اپ', 'وز', 'یش', 'ن', '__eow', 'کے', '__sow', 'رہ', 'نم', 'ا', '__eow', '__sow', 'بھ', 'ی', '__eow', '__sow', 'مو', 'ج', 'و', 'د', '__eow', '__sow', 'ہو', 'نگ', 'ے', '__eow', '__sow', '__unk', '__eow']\n",
      "[6, 3, 4, 10, 17, 24, 26, 27, 35, 25, 24, 33, 57, 72, 25, 8, 20, 7, 11, 24, 2, 26, 25, 24, 39, 37, 25, 24, 0, 25, 24, 44, 39, 125, 25, 24, 134, 136, 137, 30, 25, 5, 24, 139, 141, 26, 25, 24, 90, 27, 25, 24, 96, 44, 29, 31, 25, 24, 128, 91, 37, 25, 24, 0, 25]\n",
      "وزیراعظم عمران خان نے کل ایک مقام پر جانے کا فیصلہ کیا ہے __unk جہاں اپوزیشن کے رہنما بھی موجود ہونگے __unk\n",
      "Tokenized Urdu text: ['وزیراعظم', 'عمران', 'خان', 'نے', 'کل', '__sow', 'ا', 'ی', 'ک', '__eow', '__sow', 'م', 'ق', 'ام', '__eow', 'پر', 'جانے', 'کا', 'فیصلہ', '__sow', 'کی', 'ا', '__eow', '__sow', 'ہ', 'ے', '__eow', '__sow', '__unk', '__eow', '__sow', 'ج', 'ہ', 'اں', '__eow', '__sow', 'اپ', 'وز', 'یش', 'ن', '__eow', 'کے', '__sow', 'رہ', 'نم', 'ا', '__eow', '__sow', 'بھ', 'ی', '__eow', '__sow', 'مو', 'ج', 'و', 'د', '__eow', '__sow', 'ہو', 'نگ', 'ے', '__eow', '__sow', '__unk', '__eow']\n",
      "Transformed Urdu text: [6, 3, 4, 10, 17, 24, 26, 27, 35, 25, 24, 33, 57, 72, 25, 8, 20, 7, 11, 24, 2, 26, 25, 24, 39, 37, 25, 24, 0, 25, 24, 44, 39, 125, 25, 24, 134, 136, 137, 30, 25, 5, 24, 139, 141, 26, 25, 24, 90, 27, 25, 24, 96, 44, 29, 31, 25, 24, 128, 91, 37, 25, 24, 0, 25]\n"
     ]
    }
   ],
   "source": [
    "from bpe import Encoder\n",
    "test_corpus = \"\"\"وزیراعظم عمران خان نے کل ایسی جگہ جانے کا فیصلہ کر لیا کہ اپوزیشن رہنما بھی دنگ\n",
    "پاکستان کا یمن کے معاملے پر موثر کردار ادا کرنے کا فیصلہ  صدر مملکت عارف علوی  سابق وزیراعظم یوسف رضاگیلانی کے بھانجے کی گاڑی پر فائرن\n",
    "علیم خان کی جائیدادیں ملک سے باہر  تفصیلات آنے پر میرٹ پر کارروائی ہوگی ڈی جی\n",
    "سرکاری افسر اکرام نوید نے50کروڑ چرائے اور شہباز شریف کے داماد علی عمران کو 13\n",
    "وزیراعظم عمران خان نے ملک کی صورتحال میں بہتری کے لیے حتمی وقت دے دیاحالات\n",
    "سیاسی جماعتیں اداروں کوگالیاں دینے والوں کیخلاف متحد ہوجائیں فیصل واڈا\n",
    "عمران خان کو عاشق رسول ﷺ قرار دلوانے کیلئے فیصل آباد کے مولانا کودھمکیاں دی\n",
    "نوازشریف کےخلاف فلیگ شپ ریفرنس کی سماعت آج ہوگی\n",
    "آسیہ بی بی کی بیرون ملک روانگی کی خبریں درست نہیںترجمان دفترخارجہ\n",
    "وزیراعظم عمران خان کی زیر صدارت وفاقی کابینہ کا اجلاس آج ہوگ\"\"\"\n",
    "\n",
    "\n",
    "encoder = Encoder(200, pct_bpe=0.88)  # params chosen for demonstration purposes\n",
    "encoder.fit(test_corpus.split('\\n'))\n",
    "\n",
    "example=\"وزیراعظم عمران خان نے کل ایک مقام پر جانے کا فیصلہ کیا ہے، جہاں اپوزیشن کے رہنما بھی موجود ہونگے۔\"\n",
    "print(encoder.tokenize(example))\n",
    "print(next(encoder.transform([example])))\n",
    "print(next(encoder.inverse_transform(encoder.transform([example]))))\n",
    "\n",
    "# Tokenize and transform the example Urdu text\n",
    "tokenized_urdu = encoder.tokenize(example)\n",
    "transformed_urdu = next(encoder.transform([example]))\n",
    "#inverse_transformed_urdu = next(encoder.inverse_transform(transformed_urdu))\n",
    "\n",
    "# Print the results\n",
    "print(\"Tokenized Urdu text:\", tokenized_urdu)\n",
    "print(\"Transformed Urdu text:\", transformed_urdu)\n",
    "#print(\"Inverse transformed Urdu text:\", inverse_transformed_urdu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69365aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: ['ÙĪØ²ÛĮØ±Ø§Ø¹Ø¸Ùħ', 'ĠØ¹ÙħØ±Ø§ÙĨ', 'ĠØ®Ø§ÙĨ']\n",
      "Decoded: وزیراعظم عمران خان\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Preprocess the text: remove punctuations and unnecessary characters\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuations and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "# Load your dataset or corpus\n",
    "corpus = \"\"\"\n",
    "وزیراعظم عمران خان نے کل ایسی جگہ جانے کا فیصلہ کر لیا کہ اپوزیشن رہنما بھی دنگ\n",
    "پاکستان کا یمن کے معاملے پر موثر کردار ادا کرنے کا فیصلہ ، صدر مملکت عارف علوی  سابق وزیراعظم یوسف رضاگیلانی کے بھانجے کی گاڑی پر فائرن\n",
    "علیم خان کی جائیدادیں ملک سے باہر ، تفصیلات آنے پر میرٹ پر کارروائی ہوگی ڈی جی\n",
    "سرکاری افسر اکرام نوید نے50کروڑ چرائے اور شہباز شریف کے داماد علی عمران کو 13\n",
    "وزیراعظم عمران خان نے ملک کی صورتحال میں بہتری کے لیے حتمی وقت دے دیا،حالات\n",
    "سیاسی جماعتیں اداروں کوگالیاں دینے والوں کیخلاف متحد ہوجائیں فیصل واڈا\n",
    "عمران خان کو عاشق رسول ﷺ قرار دلوانے کیلئے فیصل آباد کے مولانا کودھمکیاں دی\n",
    "نوازشریف کےخلاف فلیگ شپ ریفرنس کی سماعت آج ہوگی\n",
    "آسیہ بی بی کی بیرون ملک روانگی کی خبریں درست نہیں،ترجمان دفترخارجہ\n",
    "وزیراعظم عمران خان کی زیر صدارت وفاقی کابینہ کا اجلاس آج ہوگا\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the corpus\n",
    "preprocessed_corpus = preprocess_text(corpus)\n",
    "\n",
    "# Save the preprocessed corpus to a file\n",
    "with open(\"urdu_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(preprocessed_corpus)\n",
    "\n",
    "# Initialize Byte Pair Encoding (BPE) tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Train BPE tokenizer on the preprocessed corpus file\n",
    "tokenizer.train(\"urdu_corpus.txt\", vocab_size=1000)\n",
    "\n",
    "# Specify directory to save the model\n",
    "model_dir = \"urdu_bpe_model\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save the trained tokenizer to the specified directory\n",
    "tokenizer.save_model(model_dir)\n",
    "\n",
    "# Load the trained tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer.from_file(os.path.join(model_dir, \"vocab.json\"), os.path.join(model_dir, \"merges.txt\"))\n",
    "\n",
    "# Example encoding and decoding\n",
    "encoded = tokenizer.encode(\"وزیراعظم عمران خان\")\n",
    "print(\"Encoded:\", encoded.tokens)\n",
    "\n",
    "decoded = tokenizer.decode(encoded.ids)\n",
    "print(\"Decoded:\", decoded)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
